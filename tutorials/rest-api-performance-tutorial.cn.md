## 优化服务器性能: 如何做一个快速的服务API
- 作者：张宇瀚  2021年1月16日

程序员经过几年工作，都基本掌握了些编程技能。然而服务器上往往会有很多不同人写的程序，程序的质量良莠不齐。能在运营中发现性能问题，保证一个快速的服务器，这点甚至比写优质的程序本身更加重要。这篇文章主旨于介绍发现性能问题。

# 为什么要服务API?
  为前端工程师提供数据，方便团队开发。种种原因在此不罗列。

## 为什么要Micro Service微服务?
- 把数据库分开和微服务联系起来，变成简单的API。方便更新，出错了方便分析。
- 由于直接和数据库相连速度很快(小于1微秒)，微服务通常不需要多线程。

## 为什么要Backend For Frontend（服务于前端的后端)?
- Backend For Frontend 把多个微服务数据联系到一起。方便前端使用，减少前端需要呼叫后端的次数。或者多种数据进行需要的计算。
- 通常需要多线程或非阻塞同时呼叫多个微服务。

# 什么是快的服务API ?

  服务器响应速度通常在NginX访问记录里出现(Access log)。服务器响应速度直接影响网页的速度，服务器测量的标准平均响应微秒数通常是不够的。常用测量的是99%的访问速度。这个值代表了最差用户体验。作为服务器的速度底线。
  - 为什么不用最大时间测量? 通常会有误差和种种不可控制的网络问题。去掉最慢1%甚至0.1%。相当于体操比赛评分去掉一个最低分。

  - upstream_response 和 request_time 的区别
    - upstream_response: 服务器响应的的一个字节需要的时间。也就是说服务器已经完成逻辑开始传输了。通常这适合测量程序本身是否快。
    - request_time: 服务器响应后彻底完成传输的时间。这里测量的包括网络传输的速度。直接测量用户体验。注意如果用户的网速慢或者电脑慢也会影响这个速度。

## 一般应该有多快才算快？
- micro service 微服务: 在10ms以内 （微秒）
- 数据库响应速度: 小于1ms （微秒）
- Backend For Frontend （服务于前端的后端): < 小于 200ms（微秒）
- 写操作: 一秒以内

# 测量快不快方法
- print - 相信大家在某种阶段都用过这种在程序里加print的方法测量。由于stdout输出本身会带慢程序。通常在程序里做测量会测不准。
- NginX log 服务器访问记录 - 服务器响应速度的用户体验都在这里了。快慢最终标准。
- Profiler 分析器 - 有VisualVM 可以直接在本地或者远程（通过JMX连接）测量Java程序。可以自动告诉你哪个函数累积的时间最多。通常会是最慢的部分。
- StatsD - 通过 UDP 传输测量值的。开发者根据需要在程序里加测量值。由于UDP 没有连接过程，并不会造成减速或因为出错而干扰正常逻辑运行。用Graphite 或 Grafana 把Stats收集来的数据做图表来看99%的速度
- APM (application performance monitoring) (newrelic)
- DB slow log 数据库慢记录 - 通常数据库会有记录下很慢访问的功能。这样不用有程序也能知道那些查询造成了减速。

# 怎么才能快？

对一般的网站来说，往往只是数据读写，是没有过多复杂算法的。所以不需要很多CPU资源。所以对这种程序我们一般假设**只要服务器没有用尽任何资源就会无穷快**。这里的资源包括CPU, 内存, 网络带宽。等等。

## 程序用尽内存会怎样？
对于C/C++程序来说，通常意味着程序退出。对于有虚拟机（例如Java），这种情况通常有两种:
- 1. 程序的内存上限大于真正的内存，这时程序向系统索要内存得不到，会因此出错退出。这种情况通常可以给程序设一个内存上限来避免。
- 2. 程序的内存上限小于真正的内存保护上一种情况不会发生。这时程序虚拟机会触发GC事件(清理垃圾)释放可以重复使用的内存。**这时会造成高CPU，延缓程序速度。**
  - 多个CPU对GC事件(清理垃圾)比单个CPU 有帮助。

### 为什么会用尽内存？
- 如果一切正常的情况，一起来的用户太多了，每个用户访问占一部分内存，用尽了内存。
  - 因为线程类服务器程序, 每个线程都要占用很多内存。例如 tomcat通常只会给 200个线程。用非阻塞 nonblocking 类服务器程序(例如 NodeJS, Spring Boot)可以脱离每个用户都占一个线程的限制。从而允许更多用户同时访问。
  - 用用非阻塞一定就快吗？
    - 其他情况仍会带慢程序。
- 程序有内存泄漏:
  - 这种情况程序的内存尺寸记录会告诉你内存在不停减少。GC事件(清理垃圾)也会不到原来的大小。这是就要注意了。
  - 约束内存缓存: 在使用缓存时，应该给在本地的内存设个上限。不要用完。
    - 用soft-reference能够保证，在没有内存的情况下，缓存会被清空，释放为程序可用内存。
### 为什么 CPU 会慢？
  - 同一台机器内会有很多不同程序。查一下是否其他程序占用 CPU 资源

### 读写硬盘会慢
- 因为硬盘读写慢，服务器应该通过网络去数据库读数据。
- 当程序出错时，往往会在写出错记录时花费更多时间，带慢程序。开发者应该减少写出错记录的长度。

### Thread Pool 线程池用完了
- 当Tomcat 线程用完了，更多用户会阻塞在程序等线程。这时访问就变慢了。
- 其他线程池 (Thread Pool): 根据具体程序的设置，线程池可能被设置成用完就等待。
  - 线程池最好的设置是用完就出错。以保证开发人员知道自己没给够资源。

### Connection pool 连接池用完了
- 程序内做数据库访问，HTTP访问，通常会有客户端。客户端里会有连接池。连接池用完时，会造成阻塞等待连接的现象。因为消耗内存不多，连接池通常应该设置的远大于需要的范围。

### Network bandwidth (带宽)
- 你的服务器带宽用完了。阻塞在下载上。可能你的服务器在传输很大的视频等等。通常在内网带宽很大这种事不会发生。

#### 减少下载字节
很明显，下载文字要比下载视频快。尽管服务器带宽很大，但也一样越短的越快。
很多程序员很懒，会把表格一整行不需要的数据一起拿下来。传输不需要的数据造成了速度变慢。
 - 这是使用ORM 经常会犯的错误。很多程序员假设 ORM 帮他们不下载不必要的数据。然后未设置的ORM 通常会读取一整行。
 - API 应该使用 partial response 设计。减少不必要的数据。GraphQL 是一个很好的选择。
- 压缩 (compression): 即时压缩会占用 CPU ，如果传输的数据大时，压缩会有很大功效。尤其是传输到外网时。
- 减少 HTTP header:
- 减少 round-trip
  - batch
  - join
- 平行下载


怎么DB才能快？
- use index
  - high CPU
- fit in memory
- use SSD (write faster)
- use slow log
- use db metrics
- nosql compaction
- batch write
- batch read

为什么会慢？
- 出错太多
  - log 记录很慢
- 网络环境
- DNS resolve
- using up CPU
  - 多加一个CPU管用吗？
    - 如果算法无法改进，认输砸钱
  - 优化算法
    - 散列算法、哈希函数
    - 对分搜索
    - 线性搜索
    - 递归调用
- 缓存变数据库
- using up memory
  - GC = using up CPU
  - 内存泄漏 Memory leak
- 内存太大, GC太长


怎么才能受得住很多人一起来？
- 快=多
  - 设时限 (timeout)
- 减少内存需要
  - nonblocking 不需要thread等待时占内存
  - nonblocking != 快
- 砸钱
  - 认输
  - 多台服务器分流

你的工作就是这个少花钱少错误上人多不让他变慢的游戏。
